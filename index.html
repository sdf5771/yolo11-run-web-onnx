<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLO11 Run Web ONNX</title>
    <!-- ONNX Runtime CDN -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.16.3/dist/ort.min.js"></script>
    <script>
        // WASM 파일 경로 설정
        const ort = window['ort'];
        const ortWasmBackendPath = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.16.3/dist/';
        ort.env.wasm.wasmPaths = ortWasmBackendPath;
    </script>
    <!-- TensorFlow.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
</head>
<body>
    <main style="display: flex; flex-direction: column; align-items: center;">
        <input type="file" id="fileInput" accept="image/*">
        <canvas id="canvas" style="margin-top: 10px; border: 1px solid #000;"></canvas>
    </main>  
    
    <script type="text/javascript">
        const fileInput = document.querySelector('#fileInput');
        const canvas = document.querySelector('#canvas');
        const cocoClassesDataSet = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
            'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
            'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
            'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
            'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',
            'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ];

        const getImageTensorFromPath = async (path) => {
            return new Promise((resolve, reject) => {
                try {
                    const imageElement = new Image();
                    imageElement.src = path;
                    // 이미지 로드 완료 후 텐서로 변환
                    imageElement.onload = () => {
                        const tensor = tf.browser.fromPixels(imageElement);
                        resolve(tensor);
                    }
                } catch (error) {
                    reject(error);
                }
            });
        }

        const preProcessImage = async (path) => {
            return new Promise((resolve, reject) => {
                const ctx = canvas.getContext('2d');
                const imageElement = new Image();
                
                imageElement.onload = () => {
                    // 캔버스 크기를 원본 이미지 크기로 설정 (UI 표시용)
                    canvas.width = imageElement.width;
                    canvas.height = imageElement.height;
                    
                    // 원본 이미지 그리기
                    ctx.drawImage(imageElement, 0, 0, imageElement.width, imageElement.height);
        
                    // 모델 입력용 640x640 크기의 캔버스 생성
                    const inputCanvas = document.createElement('canvas');
                    inputCanvas.width = 640;
                    inputCanvas.height = 640;
                    const inputCtx = inputCanvas.getContext('2d');
                    
                    // 이미지 비율 유지하면서 640x640에 맞게 그리기
                    const scale = Math.min(640 / imageElement.width, 640 / imageElement.height);
                    const scaledWidth = imageElement.width * scale;
                    const scaledHeight = imageElement.height * scale;
                    const offsetX = (640 - scaledWidth) / 2;
                    const offsetY = (640 - scaledHeight) / 2;
                    
                    inputCtx.drawImage(imageElement, offsetX, offsetY, scaledWidth, scaledHeight);
                    
                    // 모델 입력용 이미지 데이터 가져오기
                    const ctxImageData = inputCtx.getImageData(0, 0, 640, 640);
                    const red = [], green = [], blue = [];
                    for (let i = 0; i < ctxImageData.data.length; i += 4) {
                        red.push(ctxImageData.data[i]);
                        green.push(ctxImageData.data[i + 1]);
                        blue.push(ctxImageData.data[i + 2]);
                    }
                    const imageInput = [...red, ...green, ...blue];
                    resolve([imageInput, 640, 640]); // 고정된 크기 반환
                };
                
                imageElement.onerror = () => {
                    reject(new Error('이미지 로드 실패'));
                };
                
                imageElement.src = path;
            });
        }

        /**
         * 사용 중인 브라우저의 WebGPU 지원 여부에 따라 WebGPU 또는 WASM 모델을 로드
         * @returns {Promise<ort.InferenceSession>}
        */
        const loadOptimizedModel = async () => {
            try {
                // 더 자세한 디버깅 정보
                ort.env.debug = true;
                ort.env.logLevel = 'verbose';

                // fetch를 사용한 모델 로드 방식
                const response = await fetch(modelPath);
                if (!response.ok) {
                    throw new Error(`모델 로드 실패: ${response.status} ${response.statusText}`);
                }
                
                const modelBuffer = await response.arrayBuffer();
                console.log('모델 파일 로드 완료, 크기:', modelBuffer.byteLength);

                // 모델 경로
                const modelPath = "./yolo11n.onnx";

                // 모델 옵션
                const options = {
                    graphOptimizationLevel: 'all',
                    enableCpuMemArena: true,
                    executionMode: 'sequential',
                    enableOrtCustomOps: true
                };

                // WebGPU 지원 여부 확인
                if(navigator.gpu) {
                    try {
                        // WebGPU 모델 로드
                        options.executionProviders = ['webgpu'];
                        return await ort.InferenceSession.create(modelPath, options);
                    } catch (error) {
                        console.error('WebGPU 지원 없음:', error);
                    }   
                }
                
                // WASM 모델 로드
                options.executionProviders = ['wasm'];
                return await ort.InferenceSession.create(modelPath, options);
            } catch (error) {
                console.error('모델 로드 오류:', error);
                throw error;
            }
        }

        const runModel = async (imageInput, width, height) => {
            try {
                const model = await loadOptimizedModel();
                console.log('모델 세션 생성 완료');
                
                // 모델의 입력 및 출력 이름 확인
                const inputNames = model.inputNames;
                const outputNames = model.outputNames;
                console.log('모델 입력 이름:', inputNames);
                console.log('모델 출력 이름:', outputNames);
                
                // 입력 이름이 배열에서 첫 번째 항목을 사용
                const inputName = inputNames[0];
                console.log('사용할 입력 이름:', inputName);
                
                const inputTensor = new ort.Tensor('float32', Float32Array.from(imageInput), [1, 3, width, height]);
                console.log('모델 입력 텐서 생성 완료, 형태:', [1, 3, width, height]);
                
                // 동적으로 입력 이름 사용
                const feeds = {};
                feeds[inputName] = inputTensor;
                
                const outputTensor = await model.run(feeds);
                console.log('outputTensor ', outputTensor);
                return outputTensor;
            } catch (error) {
                console.error('모델 실행 오류:', error);
                throw error;
            }
        }

        const postProcessImage = async (outputTensor) => {
            // 출력 텐서의 구조 확인
            console.log('출력 텐서 구조:', outputTensor);
            
            // output0 키를 사용하여 실제 텐서 데이터에 접근
            const output = outputTensor['output0'];
            console.log('출력 텐서 데이터:', output);
            
            if (!output || !output.data) {
                console.error('출력 텐서 데이터가 없습니다.');
                return null;
            }
            
            // 출력 데이터의 형태와 크기 확인
            console.log('출력 데이터 형태:', output.dims);
            console.log('출력 데이터 크기:', output.size);
            
            // YOLO11의 출력 포맷에 맞게 처리
            // 출력 형태는 일반적으로 [batch, num_boxes, box_data]
            const data = output.data;
            
            // 간단한 예시: 첫 번째 감지된 객체만 사용
            // 실제로는 여러 객체를 감지하고 신뢰도 점수에 따라 필터링해야 함
            // 여기서는 임의로 첫 번째 결과만 사용
            if (output.dims[1] > 0) {
                // 첫 번째 박스의 좌표 가져오기 (형식: [x, y, width, height, ...])
                const stride = output.dims[2]; // 박스당 데이터 개수
                return [data[0], data[1], data[2], data[3]]; // x, y, width, height
            }
            
            return null; // 감지된 객체가 없음
        }

        fileInput.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            const reader = new FileReader();
            reader.onload = async (event) => {
                const tensor = await getImageTensorFromPath(event.target.result);
                const [imageInput, width, height] = await preProcessImage(event.target.result);
                console.log('imageInput ', imageInput);
                const outputTensor = await runModel(imageInput, width, height);
                const boxes = await postProcessImage(outputTensor);
                
                if (!boxes) {
                    console.log('감지된 객체가 없습니다.');
                    return;
                }

                const ctx = canvas.getContext('2d');
                
                // 원본 이미지의 크기
                const canvasWidth = canvas.width;
                const canvasHeight = canvas.height;
                
                // 640x640에서 원본 이미지 크기로 좌표 변환
                const scale = Math.min(640 / canvasWidth, 640 / canvasHeight);
                const scaledWidth = canvasWidth * scale;
                const scaledHeight = canvasHeight * scale;
                const offsetX = (640 - scaledWidth) / 2;
                const offsetY = (640 - scaledHeight) / 2;
                
                // 바운딩 박스 좌표 변환
                const x = (boxes[0] - offsetX) / scale;
                const y = (boxes[1] - offsetY) / scale;
                const w = boxes[2] / scale;
                const h = boxes[3] / scale;
                
                ctx.strokeStyle = "red";
                ctx.lineWidth = 2;
                ctx.clearRect(0, 0, canvasWidth, canvasHeight);
                ctx.beginPath();
                ctx.rect(x, y, w, h);
                ctx.stroke();
            }
            reader.readAsDataURL(file);
        });
    </script>
</body>
</html>