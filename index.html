<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLO11 Run Web ONNX</title>
    <!-- ONNX Runtime CDN -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.16.3/dist/ort.min.js"></script>
    <script>
        // WASM 파일 경로 설정
        const ort = window['ort'];
        const ortWasmBackendPath = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.16.3/dist/';
        ort.env.wasm.wasmPaths = ortWasmBackendPath;
    </script>
    <!-- TensorFlow.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
</head>
<body>
    <main style="display: flex; flex-direction: column; align-items: center;">
        <input type="file" id="fileInput" accept="image/*">
        <h3 id="detectResult">Detect Result: </h3>
        <div id="detectResultBox" style="display: flex; flex-direction: column; margin-top: 10px; border: 1px solid #000;">

        </div>
        <canvas id="canvas" style="margin-top: 10px; border: 1px solid #000;"></canvas>
    </main>  
    
    <script type="text/javascript">
        const fileInput = document.querySelector('#fileInput');
        const canvas = document.querySelector('#canvas');
        const detectResult = document.querySelector('#detectResult');
        const detectResultBox = document.querySelector('#detectResultBox');

        // YOLO11n 모델이 지원하는 COCO 클래스 데이터셋
        const cocoClassesDataSet = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
            'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
            'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
            'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',
            'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',
            'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ];

        const getImageTensorFromPath = async (path) => {
            return new Promise((resolve, reject) => {
                try {
                    const imageElement = new Image();
                    imageElement.src = path;
                    // 이미지 로드 완료 후 텐서로 변환
                    imageElement.onload = () => {
                        const tensor = tf.browser.fromPixels(imageElement);
                        resolve(tensor);
                    }
                } catch (error) {
                    reject(error);
                }
            });
        }

        const preProcessImage = async (path) => {
            return new Promise((resolve, reject) => {
                const ctx = canvas.getContext('2d');
                const imageElement = new Image();
                
                imageElement.onload = () => {
                    // 캔버스 크기를 원본 이미지 크기로 설정 (UI 표시용)
                    canvas.width = imageElement.width;
                    canvas.height = imageElement.height;
                    
                    // 원본 이미지 그리기
                    ctx.drawImage(imageElement, 0, 0, imageElement.width, imageElement.height);
        
                    // 모델 입력용 640x640 크기의 캔버스 생성
                    const inputCanvas = document.createElement('canvas');
                    inputCanvas.width = 640;
                    inputCanvas.height = 640;
                    const inputCtx = inputCanvas.getContext('2d');
                    
                    // 이미지 비율 유지하면서 640x640에 맞게 그리기
                    const scale = Math.min(640 / imageElement.width, 640 / imageElement.height);
                    const scaledWidth = imageElement.width * scale;
                    const scaledHeight = imageElement.height * scale;
                    const offsetX = (640 - scaledWidth) / 2;
                    const offsetY = (640 - scaledHeight) / 2;
                    
                    inputCtx.drawImage(imageElement, offsetX, offsetY, scaledWidth, scaledHeight);
                    
                    // 모델 입력용 이미지 데이터 가져오기
                    const ctxImageData = inputCtx.getImageData(0, 0, 640, 640);
                    const red = [], green = [], blue = [];
                    for (let i = 0; i < ctxImageData.data.length; i += 4) {
                        red.push(ctxImageData.data[i]);
                        green.push(ctxImageData.data[i + 1]);
                        blue.push(ctxImageData.data[i + 2]);
                    }
                    const imageInput = [...red, ...green, ...blue];
                    resolve([imageInput, 640, 640]); // 고정된 크기 반환
                };
                
                imageElement.onerror = () => {
                    reject(new Error('이미지 로드 실패'));
                };
                
                imageElement.src = path;
            });
        }

        /**
         * 사용 중인 브라우저의 WebGPU 지원 여부에 따라 WebGPU 또는 WASM 모델을 로드
         * @returns {Promise<ort.InferenceSession>}
        */
        const loadOptimizedModel = async () => {
            try {
                // 더 자세한 디버깅 정보
                ort.env.debug = true;
                ort.env.logLevel = 'verbose';

                // 모델 경로
                const modelPath = "yolo11n.onnx";

                // 모델 옵션
                const options = {
                    graphOptimizationLevel: 'all',
                    enableCpuMemArena: true,
                    executionMode: 'sequential',
                    enableOrtCustomOps: true
                };

                // fetch를 사용한 모델 로드 방식
                const response = await fetch(modelPath);
                if (!response.ok) {
                    throw new Error(`모델 로드 실패: ${response.status} ${response.statusText}`);
                }
                
                const modelBuffer = await response.arrayBuffer();
                console.log('모델 파일 로드 완료, 크기:', modelBuffer.byteLength);

                // WebGPU 지원 여부 확인
                if(navigator.gpu) {
                    try {
                        // WebGPU 모델 로드
                        options.executionProviders = ['webgpu'];
                        console.log('WebGPU 모델 로드 시작');
                        return await ort.InferenceSession.create(modelPath, options);
                    } catch (error) {
                        console.error('WebGPU 지원 없음:', error);
                    }   
                }
                
                // WASM 모델 로드
                options.executionProviders = ['wasm'];
                console.log('WASM 모델 로드 시작');
                return await ort.InferenceSession.create(modelPath, options);
            } catch (error) {
                console.error('모델 로드 오류:', error);
                throw error;
            }
        }

        const runModel = async (imageInput, width, height) => {
            try {
                const model = await loadOptimizedModel();
                console.log('모델 세션 생성 완료');
                
                // 모델의 입력 및 출력 이름 확인
                const inputNames = model.inputNames;
                const outputNames = model.outputNames;
                console.log('모델 입력 이름:', inputNames);
                console.log('모델 출력 이름:', outputNames);
                
                // 입력 이름이 배열에서 첫 번째 항목을 사용
                const inputName = inputNames[0];
                console.log('사용할 입력 이름:', inputName);
                
                const inputTensor = new ort.Tensor('float32', Float32Array.from(imageInput), [1, 3, width, height]);
                console.log('모델 입력 텐서 생성 완료, 형태:', [1, 3, width, height]);
                
                // 동적으로 입력 이름 사용
                const feeds = {};
                feeds[inputName] = inputTensor;
                
                const outputTensor = await model.run(feeds);
                console.log('outputTensor ', outputTensor);
                return outputTensor;
            } catch (error) {
                console.error('모델 실행 오류:', error);
                throw error;
            }
        }

        const postProcessImage = async (outputTensor) => {
            // 출력 텐서의 구조 확인
            console.log('출력 텐서 구조:', outputTensor);
            
            // output0 키를 사용하여 실제 텐서 데이터에 접근
            const output = outputTensor['output0'];
            console.log('출력 텐서 데이터:', output);
            
            if (!output || !output.data) {
                console.error('출력 텐서 데이터가 없습니다.');
                return null;
            }
            
            // 출력 데이터의 형태와 크기 확인
            console.log('출력 데이터 형태:', output.dims);
            console.log('출력 데이터 크기:', output.size);
            
            // YOLO11의 출력 형식은 일반적으로 [1, num_detections, 85] 
            // 85 = [x, y, width, height, confidence, class_scores...]
            const data = output.data;
            const numDetections = output.dims[1];
            const detPerClass = output.dims[2]; // 85 (4 좌표 + 1 신뢰도 + 80 클래스)
            
            // 감지 정보를 담을 배열
            const detections = [];
            
            // 최소 신뢰도 임계값 설정
            const confidenceThreshold = 0.25;
            
            // 모든 감지 결과 처리
            for (let i = 0; i < numDetections; i++) {
                const startIdx = i * detPerClass;
                
                // 신뢰도 점수는 일반적으로 5번째 값
                const confidence = data[startIdx + 4];
                
                // 임계값보다 낮은 신뢰도는 무시
                if (confidence < confidenceThreshold) continue;
                
                // 좌표 정보 추출
                const x = data[startIdx + 0];
                const y = data[startIdx + 1];
                const width = data[startIdx + 2];
                const height = data[startIdx + 3];
                
                // 클래스 점수
                let maxClassScore = 0;
                let maxClassIndex = -1;
                
                // 클래스 점수 중 가장 높은 값 찾기
                for (let j = 0; j < 80; j++) {
                    const classScore = data[startIdx + 5 + j];
                    if (classScore > maxClassScore) {
                        maxClassScore = classScore;
                        maxClassIndex = j;
                    }
                }
                
                // 결과 추가
                detections.push({
                    box: { x, y, width, height },
                    confidence,
                    classIndex: maxClassIndex,
                    className: cocoClassesDataSet[maxClassIndex]
                });
                
                console.log(`Detect ${i+1}: ${cocoClassesDataSet[maxClassIndex]}, Confidence: ${confidence.toFixed(2)}`);
                const resultElement = document.createElement('span');
                resultElement.textContent = `Detect ${i+1}: ${cocoClassesDataSet[maxClassIndex]}, Confidence: ${confidence.toFixed(2)}`;
                detectResultBox.appendChild(resultElement);
            }
            
            // 가장 높은 신뢰도를 가진 객체 하나만 반환 (테스트용)
            if (detections.length > 0) {
                // 신뢰도 기준 내림차순 정렬
                detections.sort((a, b) => b.confidence - a.confidence);
                const bestDetection = detections[0];
                
                // [x, y, width, height, classIndex] 형식으로 반환
                return [
                    bestDetection.box.x, 
                    bestDetection.box.y, 
                    bestDetection.box.width, 
                    bestDetection.box.height,
                    bestDetection.classIndex
                ];
            }
            
            return null; // 감지된 객체가 없음
        }

        const initializeDetectResultBox = () => {
            detectResultBox.innerHTML = '';
        }

        fileInput.addEventListener('change', async (event) => {
            initializeDetectResultBox();
            const file = event.target.files[0];
            const reader = new FileReader();
            reader.onload = async (event) => {
                const tensor = await getImageTensorFromPath(event.target.result);
                const [imageInput, width, height] = await preProcessImage(event.target.result);
                console.log('imageInput ', imageInput);
                const outputTensor = await runModel(imageInput, width, height);
                const boxes = await postProcessImage(outputTensor);
                
                if (!boxes) {
                    console.log('감지된 객체가 없습니다.');
                    return;
                }

                const ctx = canvas.getContext('2d');
                
                // 원본 이미지의 크기
                const canvasWidth = canvas.style.width;
                const canvasHeight = canvas.style.height;
                
                // 640x640에서 원본 이미지 크기로 좌표 변환
                const scale = Math.min(640 / canvasWidth, 640 / canvasHeight);
                const scaledWidth = canvasWidth * scale;
                const scaledHeight = canvasHeight * scale;
                const offsetX = (640 - scaledWidth) / 2;
                const offsetY = (640 - scaledHeight) / 2;
                
                // 바운딩 박스 좌표 변환
                const x = (boxes[0] - offsetX) / scale;
                const y = (boxes[1] - offsetY) / scale;
                const w = boxes[2] / scale;
                const h = boxes[3] / scale;
                
                ctx.strokeStyle = "red";
                ctx.lineWidth = 2;
                ctx.clearRect(0, 0, canvasWidth, canvasHeight);
                ctx.beginPath();
                console.log(x, y, w, h);
                ctx.rect(x, y, w, h);
                ctx.stroke();

                detectResult.textContent = `Detect Result: ${cocoClassesDataSet[boxes[4]]}`;
            }
            reader.readAsDataURL(file);
        });
    </script>
</body>
</html>